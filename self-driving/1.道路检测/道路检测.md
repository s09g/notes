# Lanes Finding with Computer Vision

利用计算机视觉进行道路检测，一般包括6部分：摄像头校正(camera calibration)、图像失真校正(distortion correction)、色彩/梯度二值化(color/gradient threshold)、视角转换 Perspective transform 、行道线检测(Detect lane lines)、 道路弯度测量(Determine the lane curvature)

### Calibration 校正
首先要对失真的程度进行测量，然后根据measurement的结果进行undistort

![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/1.jpeg)
这个东西叫做chessboard pattern, 用的时候从不同的角度拍这个chessboard，利用的是每个方块的corner去校正 (图像要记得转成灰度图)
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/2.jpeg)
得到的结果其实只跟拍照的相机有关。对于每个的镜头，要单独做一遍这种校正。

### Distorition 图像失真
理论上，只要不是针孔摄像机，基本都会存在图像失真的问题（透镜成像更快点，针孔相机这点上比不了）
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/3.jpeg)
图像失真会影响到道路检测（将直线判断成曲线），车辆检测（用CNN检测的时候，识别出来的车比实际更大或者更小）
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/4.jpeg)
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/5.jpeg)

由透镜引起的失真主要是两个: <br>
+ **径向畸变(Radial Distortion)**<br> 原因是光线穿过透镜的边缘时发生的偏转大于穿过中心发生的偏转
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/6.jpeg)

+ **切线畸变(Tangential Distortion)**<br>
原因是光线穿过透镜之后并没有垂直打在成像平面上
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/7.jpeg)

### ROI (Region of Interest)
道路检测要先从摄像头视角获取道路信息，然后选取**ROI(目标区域)**, 包括选颜色和选区域。

选颜色比较接近直觉, 路上的线也就两种颜色，要么白线，要么黄线。
白线其实比较好找
![color selection](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/8.jpeg)

但是黄线的话就不能直接用原图了。要先把原图分成RGB三层
![yellow line](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/9.jpeg)

而黄色的线在蓝色那层是看不到的 
![RGB](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/10.jpeg)
（因为是互补色）
![光的三原色](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/11.jpeg)

选区域是可以直接利用CV解决的问题。<br>
从车头视角向前看，大部分像素都是没有用的。尤其是天空的部分。对于自动驾驶来说差不多等价于干扰信号，基本上可以直接过滤掉
![车头视角](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/12.jpeg)
![区域选择](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/13.jpeg)

### Color Space 色彩空间

在RGB色彩空间（以RGB建立三维空间）中，白色是由红绿蓝三种颜色的最大值组成的。
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/14.jpeg)
因此想获得白线，可以通过设置RGB值的阈值
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/15.jpeg)

但是这种情况下，会丢失黄线的信息。一般的处理方式是使用别的色彩空间，比如HSV, HLS, LUV...
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/16.jpeg)
其中HSV（色相、饱和度、明度）和HLS（色相、亮度、饱和度）使用最多

### HLS (hue, saturation, lightness)
也叫HSL，甚至叫HSL的还更多点。
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/17.jpeg)
其实图像本身在光亮条件下变化最大，HS信道一般倒是不怎么变。所以我们把图像按照HSL拆分，在S信道下黄线非常明显
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/18.jpeg)

### Canny Edge Detection
下一步是使用边缘检测算法寻找边线。如果我们把视图当成一张灰度图来看待，那么每一条边其实都在明暗块交替的位置
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/19.jpeg)
通过计算亮度的变化，可以把原图转化成一张梯度图

![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/20.jpeg)
然后再将结果锐化，得到亮度数值变化最大的像素点
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/21.jpeg)

实际上，在做Canny算法之前，要对图像做**高斯平滑(Gaussian smoothing / Gaussian Blur)** ，消除噪声和伪梯度点

#### (题外话) Sobel Operator 索伯算子 
首先，为什么卷积神经网络会有卷积(convolution)这种操作…<br>
看完Sobel算子总算懂了，卷积这种运算讲究的是一个信号叠加。相比于Canny边缘检测，Sobel边缘检测其实更容易理解（然而还是Canny效果好）。

### Hough Transform 霍夫变化

Hough Transform是图像变化中的经典算法，主要用来寻找图像中符合某种特征的集合，说白了就是检测直线、圆、椭圆。<br>
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/22.jpeg)
Hough变化要将笛卡尔坐标下的点变化到霍夫极坐标系，原来的点共线问题会由此转化计算成曲面在极坐标下的共点，效果上就是该算法对边缘间断不敏感。大致上是这个意思，实际操作的时候是统计累加空间里的局部最大值（峰值），以该峰值作为结果（所以说抗噪能力还是很强的）。
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/23.jpeg)

总结一下就是：<br>
原图 -> 灰度图 -> 边缘检测 -> 直线检测 -> 过滤掉斜率过低的直线 -> 将最后结果叠加回原图

![原图](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/24.jpeg)
![灰度图&边缘检测](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/25.jpeg)
![最后结果叠加回原图](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/26.jpeg)

### Perspective Transform
由于Perspective的存在，2D图像存在近大远小的现象
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/27.jpeg)
这样会导致原本平行的行道线，出现汇聚的趋势
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/28.jpeg)
因此需要把视角转换成俯视
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/29.jpeg)
将行道线还原到平行
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/31.jpeg)

### Lane Curvature
解决道路弯曲(Lane Curvature)问题，实际上比较复杂。先要依次校正原图
![lc](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/32.jpeg)
选取ROI
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/33.jpeg)
然后要进行**视角转换(Perspective Transform)**
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/34.jpeg)
最后根据俯视图(Top-down view) 用二次函数拟合行道线
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/35.jpeg)

### Sliding windows 滑动窗口
在检测弧线的过程中，首先在图像底部选取一小段，在垂直方向做直方图
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/36.jpeg)
将顶点连接，变成峰值图
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/37.jpeg)
出现峰值的地方是行道线的位置
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/38.jpeg)
以此为起点，使用逐步向上移动，每次处理一小段图像
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/39.jpeg)
这种检测模式叫做滑动窗口
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/40.jpeg)
一旦拥有了第一帧的行道线位置，在随后的检测中可以利用边缘检测 + ROI 的方式获得之后的行道线
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/41.jpeg)

得到道路的二次函数并没有用，从驾驶的角度来看，真正需要的是当前的转弯弧度。所以需要求出图片组的曲率半径(radius of curvature)，在对应计算出现实中的曲率半径
![](https://github.com/s09g/notes/raw/master/self-driving/1.%E9%81%93%E8%B7%AF%E6%A3%80%E6%B5%8B/assets/42.jpeg)

---

*此外还有一些小的细节，包括Offset, Sanity Check, Look-Ahead Filter, etc. 篇幅有限，不一一赘述*
