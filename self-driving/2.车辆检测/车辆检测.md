# Vehicle Detection 车辆检测
在 **CNN (Convolutional Neural Networks 卷积神经网络)** 普遍运用之前，车辆检测是通过使用条件随机场或者SVM(支持向量机)来实现的。操作上分为两步，先是从图像上提取特征，然后基于特征建立模型，判断车辆位置。

### template matching 模板匹配

对于图像上的每一块颜色，计算与背景图的distance
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/1.jpeg)

甚至更硬核一点，直接把各种可能的车辆图片存起来，然后跟相机视角的图片进行比较
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/2.jpeg)
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/3.jpeg)

这类解决方案统称 **template matching**
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/4.jpeg)

### Color Histogram
template matching的缺陷也很明显，对于没有预存过的模板，自然无从识别。因此出现了 Color Histogram方案
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/5.jpeg)
将车辆的模板转换成颜色直方图，运算时比较目标物体与预存直方图的相似度。优点是同一个物体在不同角度仍可识别。比如对于一辆红色的车，从不同方向看过去，模板匹配无法很好地识别，而利用Color Histogram则不受影响。

### HOG 
Histogram of Oriented Gradients (定向梯度直方图), 相比于之前的特征，HOG特征更加健壮，并且无视颜色的影响。

操作的时候，首先捕捉图像的轮廓与纹理信息
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/6.jpeg)
然后将图像划分为多个cell。对每个cell计算梯度方向
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/7.jpeg)
统计每个cell的局部直方图
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/8.jpeg)
将结果归一化，得到的主方向将成为局部特征梯度方向
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/9.jpeg)
汇总每个cell得到的局部信息，就可以得到HOG特征
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/10.jpeg)

### Features Combination
首先是数据预处理，这里主要是进行特征组合。

比如HOG特征是针对**梯度信息**的特征，HSV特征则是针对**颜色信息**的特征
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/11.jpeg)
可以直接将二者拼接，得到**颜色+梯度**的组合信息
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/12.jpeg)
这里面有一些要注意的地方，一般多个特征拥有不同的模量，所以数字上相差很大
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/13.jpeg)
那么就需要进行正则化，将数据对齐
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/14.jpeg)
还可以利用决策树等方法，舍弃影响不大的变量
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/15.jpeg)

### Sliding Windows
使用滑动窗口进行车辆检测，在这种场景下有一些机巧

首先还是ROI, 车辆其实只会出现在图片的下半块区域
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/16.jpeg)
其次可以预先设定好车辆可能的最大宽度和最小宽度
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/17.jpeg)

这样在检测时进行有限的multi-scale window
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/18.jpeg)
减小搜索空间
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/19.jpeg)

### Multiple Detection
最后对于同一车辆的Multiple Detection
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/20.jpeg)
建立**heat-map**，计算中心位置
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/21.jpeg)
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/22.jpeg)

### Build Model & Tracking
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/23.jpeg)
模型的选取倒是比较简单，SVM, Decision Tree, Nerual Network, etc. 这些都是常见的选择
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/24.jpeg)
针对每一帧图像，检测车辆位置，形成连续追踪
![](https://github.com/s09g/notes/raw/master/self-driving/2.%E8%BD%A6%E8%BE%86%E6%A3%80%E6%B5%8B/assets/25.jpeg)